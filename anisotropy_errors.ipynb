{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Errors in Anisotropy Estimation\n",
    "\n",
    "As in every image analysis pipeline, there are several possible errors that contribute to its wrong estimation. Understanding the effects of each kind of error will help us find the adequate corrections for them. We will analyze here the following sources:\n",
    "\n",
    "- Errors in Intensity Estimation\n",
    "- Errors in shift registration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Errors in Intensity Estimation\n",
    "\n",
    "Adequate intensity estimation requires that the images are corrected for inhomogeneities in illumination and background. What are the effects of imperfect corrections of these sources? How are these appreciated in experiments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import anisotropy_functions as af\n",
    "from cell_sim import Cell, Biosensor, Microscope, Corrector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(I_factor=(0, 2000, 100), \n",
    "          a_dimer=(0, 0.4, 0.02), a_monomer=(0, 0.4, 0.02), \n",
    "          e_par=(-1000, 1000, 50), e_per=(-1000, 1000, 50))\n",
    "def plot(I_factor=1000, a_dimer=0.22, a_monomer=0.3, e_par=-400, e_per=-400):\n",
    "    monomer_fraction = 1 / (1 + np.exp(-np.arange(-50, 50)/6))\n",
    "    anisotropy = af.anisotropy_from_monomer(monomer_fraction, a_monomer, a_dimer, 1)\n",
    "    total_fluo = af.total_fluorescence_from_monomer(monomer_fraction, 1, I_factor)\n",
    "    I_parallel = af.intensity_parallel_from_anisotropy(anisotropy, total_fluo) + e_par\n",
    "    I_perpendicular = af.intensity_perpendicular_from_anisotropy(anisotropy, total_fluo) + e_per\n",
    "    anisotropy_from_int = af.anisotropy_from_intensity(I_parallel, \n",
    "                                                       I_perpendicular)\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 1, sharex=True, figsize=(5, 7))\n",
    "    \n",
    "    axs[0].plot(I_parallel, c='g', label='Parallel')\n",
    "    axs[0].plot(I_perpendicular, c='b', label='Perpendicular')\n",
    "    axs[0].plot(I_parallel - e_par, c='g', alpha=0.5, label='Real Parallel')\n",
    "    axs[0].plot(I_perpendicular - e_per, c='b', alpha=0.5, label='Real Perpendicular')\n",
    "    axs[0].legend()\n",
    "    axs[0].set_ylabel('Intensity (u.a.)')\n",
    "    \n",
    "    axs[1].axhline(y=a_dimer, color='k', ls='--')\n",
    "    axs[1].axhline(y=a_monomer, color='k', ls='--')\n",
    "    axs[1].plot(anisotropy_from_int, color='r', label='Estimated')\n",
    "    axs[1].plot(anisotropy, color='r', alpha=0.5, label='Real')\n",
    "    axs[1].set_ylabel('Anisotropy')\n",
    "    axs[1].legend()\n",
    "\n",
    "    plt.subplots_adjust(hspace=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to notice that there different monomer and dimer anisotropies are possible depending on the errors. We must highlight that in some cases monomer anisotropy might be higher than dimer anisotropy, and this looks like a reversed anisotropy curve. Aditionally, theoritacally impossible values are also possible depending on the magnitude of the errors. Furthermore, if the error in intensity has a time dependance this will affect the shape of the curve. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Errors in shift registration\n",
    "\n",
    "Due to the thickness of high quality polarizers, it is likely that parallel and perpendicular images are shifted between each other. If we were to generate an anisotropy image, we need to be able to correct this shift. What happens if this is not adequately corrected? How can we bypass these problems? How can we estimate the best correction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by generating a simulated squared cell with a gradient of concentration of biosensors. We can choose the maximum number of biosensors expected and if we are to add poisson noise to this number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proteins = 800\n",
    "poisson = True\n",
    "\n",
    "cell = Cell(proteins, poisson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cell.cell_image, interpolation='none')\n",
    "plt.colorbar()\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define an anisotropy state for the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anisotropy = 0.26\n",
    "cell.add_biosensor({'anisotropy_monomer':0.3, 'anisotropy_dimer': 0.22, 'delta_b': 0.15})\n",
    "\n",
    "cell.generate_intensity_images(anisotropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(8, 8))\n",
    "axs = axs.flatten()\n",
    "\n",
    "this_im = axs[0].imshow(cell.parallel_image, interpolation='none')\n",
    "fig.colorbar(this_im, ax=axs[0])\n",
    "\n",
    "axs[0].axis('off')\n",
    "axs[0].set_title('Parallel Image')\n",
    "\n",
    "this_im = axs[1].imshow(cell.perpendicular_image, interpolation='none')\n",
    "fig.colorbar(this_im, ax=axs[1])\n",
    "\n",
    "axs[1].axis('off')\n",
    "axs[1].set_title('Perpendicular Image')\n",
    "\n",
    "axs[2].hist(cell.parallel_image[200:800, 200:800].flatten(), bins=100, log=True)\n",
    "axs[2].set_title('Parallel Image Histogram')\n",
    "\n",
    "axs[3].hist(cell.perpendicular_image[200:800, 200:800].flatten(), bins=100, log=True)\n",
    "axs[3].set_title('Perpendicular Image Histogram')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should estimate now the anisotropy image before adding acquisition noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_acquired_anisotropy_image = np.zeros_like(cell.parallel_image)\n",
    "nonzeros = cell.mask\n",
    "non_acquired_anisotropy_image[nonzeros] = af.anisotropy_from_intensity(cell.parallel_image[nonzeros], cell.perpendicular_image[nonzeros])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "this_im = axs[0].imshow(non_acquired_anisotropy_image, vmin=0.19, vmax=0.4, interpolation='none')\n",
    "axs[0].axis('off')\n",
    "fig.colorbar(this_im, ax=axs[0])\n",
    "\n",
    "axs[1].hist(non_acquired_anisotropy_image[cell.mask].flatten(), bins=np.arange(0.2, 0.3, 0.001))\n",
    "axs[1].axvline(x=anisotropy, color='k', ls='--')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After obtaining both intensity images, we could add some aquisition noise to the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "microscope = Microscope()\n",
    "\n",
    "parallel_image, perpendicular_image = microscope.acquire_cell(cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(8, 8))\n",
    "axs = axs.flatten()\n",
    "\n",
    "this_im = axs[0].imshow(parallel_image, interpolation='none')\n",
    "fig.colorbar(this_im, ax=axs[0])\n",
    "\n",
    "axs[0].axis('off')\n",
    "axs[0].set_title('Parallel Image')\n",
    "\n",
    "this_im = axs[1].imshow(perpendicular_image, interpolation='none')\n",
    "fig.colorbar(this_im, ax=axs[1])\n",
    "\n",
    "axs[1].axis('off')\n",
    "axs[1].set_title('Perpendicular Image')\n",
    "\n",
    "axs[2].hist(parallel_image.flatten(), bins=100, log=True)\n",
    "axs[2].set_title('Parallel Image Histogram')\n",
    "\n",
    "axs[3].hist(perpendicular_image.flatten(), bins=100, log=True)\n",
    "axs[3].set_title('Perpendicular Image Histogram')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anisotropy_image = np.zeros_like(parallel_image)\n",
    "nonzeros = cell.mask\n",
    "anisotropy_image[nonzeros] = af.anisotropy_from_intensity(parallel_image[nonzeros], perpendicular_image[nonzeros])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "this_im = axs[0].imshow(anisotropy_image, interpolation='none')\n",
    "axs[0].axis('off')\n",
    "fig.colorbar(this_im, ax=axs[0])\n",
    "\n",
    "axs[1].hist(anisotropy_image[cell.mask].flatten(), bins=100)\n",
    "axs[1].axvline(x=anisotropy, color='k', ls='--')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to add the image analysis steps and corrections we would normally implement to test them and choose the best option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrector = Corrector()\n",
    "corrected_parallel, corrected_perpendicular = corrector.correct(parallel_image, perpendicular_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(8, 8))\n",
    "axs = axs.flatten()\n",
    "\n",
    "this_im = axs[0].imshow(corrected_parallel, interpolation='none')\n",
    "fig.colorbar(this_im, ax=axs[0])\n",
    "\n",
    "axs[0].axis('off')\n",
    "axs[0].set_title('Parallel Image')\n",
    "\n",
    "this_im = axs[1].imshow(corrected_perpendicular, interpolation='none')\n",
    "fig.colorbar(this_im, ax=axs[1])\n",
    "\n",
    "axs[1].axis('off')\n",
    "axs[1].set_title('Perpendicular Image')\n",
    "\n",
    "axs[2].hist(corrected_parallel.flatten(), bins=100, log=True)\n",
    "axs[2].set_title('Parallel Image Histogram')\n",
    "\n",
    "axs[3].hist(corrected_perpendicular.flatten(), bins=100, log=True)\n",
    "axs[3].set_title('Perpendicular Image Histogram')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_anisotropy_image = np.zeros_like(corrected_parallel)\n",
    "nonzeros = np.nonzero(corrected_parallel)\n",
    "corrected_anisotropy_image[nonzeros] = af.anisotropy_from_intensity(corrected_parallel[nonzeros], corrected_perpendicular[nonzeros])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should shrink the mask to avoid border low intensity and noisy pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shrink_mask(mask, shrink=0.2):\n",
    "    inds = np.where(cell.mask[cell.mask.shape[0] //2])[0]\n",
    "    ini, end = inds[np.ceil(shrink / 2 * len(inds)).astype(int)], inds[np.floor((1 - shrink / 2) * len(inds)).astype(int)]\n",
    "\n",
    "    mask = np.zeros_like(corrected_anisotropy_image).astype(bool)\n",
    "    mask[ini:end, ini:end] = True\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = cell.mask.copy()\n",
    "mask = shrink_mask(mask, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "this_im = axs[0].imshow(corrected_anisotropy_image, cmap='plasma', vmin=0.15, vmax=0.3, interpolation='none')\n",
    "axs[0].axis('off')\n",
    "fig.colorbar(this_im, ax=axs[0])\n",
    "\n",
    "axs[1].hist(corrected_anisotropy_image[mask].flatten(), bins=np.arange(0.1, 0.45, 0.002), log=True)\n",
    "axs[1].axvline(x=anisotropy, color='k', ls='--')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to here looks like the correction worked and generated a good anisotropy image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What would happen if our shift correction was not perfect? What happens if our background correction is not perfect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(x_shift=(-20, 20, 1), y_shift=(-20, 20, 1), bkg_value=(-20, 20, 1))\n",
    "def plot(x_shift=0, y_shift=0, bkg_value=0):\n",
    "    imperfect_corrector = Corrector()\n",
    "    imperfect_corrector.bkg_params ={'bkg_value': 200 + bkg_value}\n",
    "    imperfect_corrector.shift = (-4 + x_shift, -6 + y_shift)\n",
    "    corrected_parallel, corrected_perpendicular = imperfect_corrector.correct(parallel_image, perpendicular_image)\n",
    "    \n",
    "    corrected_anisotropy_image = np.zeros_like(corrected_parallel)\n",
    "    nonzeros = np.nonzero(corrected_parallel)\n",
    "    corrected_anisotropy_image[nonzeros] = af.anisotropy_from_intensity(corrected_parallel[nonzeros], corrected_perpendicular[nonzeros])\n",
    "    \n",
    "    mask = cell.mask.copy()\n",
    "    mask = shrink_mask(mask, 0.2)\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "    this_im = axs[0].imshow(corrected_anisotropy_image, cmap='plasma', vmin=0.15, vmax=0.3, interpolation='none')\n",
    "    axs[0].axis('off')\n",
    "    fig.colorbar(this_im, ax=axs[0])\n",
    "\n",
    "    axs[1].hist(corrected_anisotropy_image[mask].flatten(), bins=np.arange(0.1, 0.45, 0.002), log=True)\n",
    "    axs[1].axvline(x=anisotropy, color='k', ls='--')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    print('Mean: %0.6f; STD: %0.6f' % (np.mean(corrected_anisotropy_image[mask].flatten()), \n",
    "                                       np.std(corrected_anisotropy_image[mask].flatten())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\Delta$b Parameter\n",
    "\n",
    "To understand the effect of this parameter, we need to simulate a curve of the fraction of monomers and translate it into anisotropy. As far as we know, deriving the curve will yield a curve proportionate to complex or, in a way, activity per unit of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = 6\n",
    "\n",
    "monomer_fraction = 1 / (1 + np.exp(-np.arange(-50, 50)/rate))\n",
    "monomer_derivative = np.diff(monomer_fraction)\n",
    "time_maximum_activity = np.where(monomer_derivative == np.max(monomer_derivative))[0][0]\n",
    "time = np.arange(0, len(monomer_fraction))\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, sharex=True, figsize=(5, 5))\n",
    "\n",
    "axs[0].plot(time, monomer_fraction)\n",
    "\n",
    "axs[1].axvline(x=time_maximum_activity, color='k', alpha=0.7, linestyle='--')\n",
    "axs[1].plot(time[:-1], np.diff(monomer_fraction))\n",
    "\n",
    "axs[0].set_ylabel('Anisotropy')\n",
    "axs[1].set_ylabel('Monomer Fraction\\nDerivative')\n",
    "axs[1].set_xlabel('Time (min.)')\n",
    "\n",
    "axs[1].set_yticks([])\n",
    "\n",
    "plt.subplots_adjust(hspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the monomer curve we can estimate the anisotropy curves by means of $\\Delta$b parameter as well as monomer and dimer anisotropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dimer=0.22\n",
    "a_monomer=0.3\n",
    "delta_b = 0.15\n",
    "@interact(a_dimer=(0.18, 0.33, 0.01), a_monomer=(0.18, 0.33, 0.01), delta_b=(-0.7, 0.8, 0.1))\n",
    "def plot(a_dimer=0.22, a_monomer=0.3, delta_b = 0.15):\n",
    "    b = 1 + delta_b\n",
    "\n",
    "    anisotropy = af.anisotropy_from_monomer(monomer_fraction, a_monomer, a_dimer, b)\n",
    "    der_ani = np.diff(anisotropy)\n",
    "    time_maximum_derivative = np.where(der_ani == np.max(der_ani))[0][0]\n",
    "\n",
    "    fig, axs = plt.subplots(3, 1, sharex=True, figsize=(5, 8))\n",
    "    axs[0].plot(anisotropy, color='r')\n",
    "\n",
    "    anisotropy_normalized = anisotropy[:-1] - np.min(anisotropy)\n",
    "    anisotropy_normalized = anisotropy_normalized / np.max(anisotropy_normalized)\n",
    "    activity = der_ani / ((1 + (b-1) * anisotropy_normalized) ** 2)\n",
    "    \n",
    "    time_maximum_activity_obs = np.where(activity == np.max(activity))[0][0]\n",
    "\n",
    "    axs[1].plot(der_ani / np.max(der_ani), color='r')\n",
    "\n",
    "    axs[2].plot(activity / np.max(activity), color='r')\n",
    "\n",
    "    axs[0].axhline(y=a_dimer, color='k', ls='--')\n",
    "    axs[0].axhline(y=a_monomer, color='k', ls='--')\n",
    "    \n",
    "    axs[1].axvline(x=time_maximum_derivative, color='k', ls='--', alpha=0.7)\n",
    "    axs[2].axvline(x=time_maximum_activity_obs, color='k', ls='--', alpha=0.7)\n",
    "    \n",
    "    axs[1].axhline(y=0, color='k')\n",
    "    axs[2].axhline(y=0, color='k')\n",
    "\n",
    "    axs[0].set_ylabel('Anisotropy')\n",
    "    axs[1].set_ylabel('Anisotropy Derivative')\n",
    "    axs[2].set_ylabel('Activity')\n",
    "    axs[2].set_xlabel('Time (min.)')\n",
    "    plt.subplots_adjust(hspace=0)\n",
    "    plt.show()\n",
    "    \n",
    "    print('Anisotropy Time: %d; Activity Time: %d' % (time_maximum_derivative, time_maximum_activity_obs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As calculating the derivative of an experimental curve is an ill-posed problem, we should assess our method to calculate its derivative. Let's define the functions we are to use to find the time of maximum activity. We should also evaluate its behaviour with noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "from scipy.interpolate import splrep, splev\n",
    "\n",
    "\n",
    "def calculate_activity(ani, time_step, delta_b=0):\n",
    "    \"\"\"Uses at least 3 points or 20 minutes to estimate the derivative of the \n",
    "    curve using Savitzky-Golay Filter.\"\"\"\n",
    "    window_length = int(np.floor(20 / time_step))\n",
    "    if window_length % 2 == 0:\n",
    "        window_length += 1\n",
    "    window_length = np.max((window_length, 3))\n",
    "    \n",
    "    der = savgol_filter(ani, window_length=window_length,\n",
    "                        polyorder=2,\n",
    "                        deriv=1, delta=time_step, mode='nearest')\n",
    "\n",
    "    anisotropy_normalized = ani - np.min(ani)\n",
    "    anisotropy_normalized = anisotropy_normalized / np.max(anisotropy_normalized)\n",
    "    activity = der / ((1 + delta_b * anisotropy_normalized) ** 2)\n",
    "    return activity\n",
    "\n",
    "def interpolate(new_time, time, curve):\n",
    "    \"\"\"Interpolate curve using new_time as xdata\"\"\"\n",
    "    if not np.isfinite(time).all():\n",
    "        return np.array([np.nan])\n",
    "\n",
    "    f = splrep(time, curve, k=3)\n",
    "    return splev(new_time, f, der=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(N=(1, 4, 1), time_resolution=(1, 20, 1), experimental_noise=(0, 0.05, 0.001), delta_b=(-0.7, 0.8, 0.1))\n",
    "def plot(N=2, time_resolution=5, experimental_noise=0.003, delta_b=0):\n",
    "    N = 10 ** N\n",
    "    monomer_fraction = 1 / (1 + np.exp(-np.arange(-50, 50)/6))\n",
    "    anisotropy = af.anisotropy_from_monomer(monomer_fraction, a_monomer, a_dimer, 1 + delta_b)\n",
    "    anisotropy_spaced = anisotropy[::time_resolution]\n",
    "    time_spaced = time[::time_resolution]\n",
    "\n",
    "    fig, axs = plt.subplots(3, 1, sharex=True, figsize=(3, 6))\n",
    "    time_maxs = []\n",
    "    for i in range(N):\n",
    "        anisotropy_exp = anisotropy_spaced + np.random.normal(0, experimental_noise, len(anisotropy_spaced))\n",
    "        activity_exp = calculate_activity(anisotropy_exp, time_step=time_resolution, delta_b=delta_b)\n",
    "        activity_interp = interpolate(time, time_spaced, activity_exp)\n",
    "        time_maxs.append(np.where(activity_interp[:-10] == np.max(activity_interp[:-10]))[0][0])\n",
    "\n",
    "        axs[0].plot(time_spaced, anisotropy_exp, alpha=0.3)\n",
    "\n",
    "        axs[1].plot(time[:-10], activity_interp[:-10], alpha=0.3)\n",
    "        \n",
    "    axs[0].plot(time, anisotropy, color='k', linewidth=3)\n",
    "    axs[0].plot(time, anisotropy, color='r')\n",
    "\n",
    "    activity_real = calculate_activity(anisotropy, time_step=1, delta_b=delta_b)\n",
    "    axs[1].plot(time, activity_real, color='k', linewidth=3)\n",
    "    axs[1].plot(time, activity_real, color='r')\n",
    "    \n",
    "    time_maximum_activity_real = np.where(activity_real == np.max(activity_real))[0][0]\n",
    "    axs[2].axvline(x=time_maximum_activity_real, color='k', alpha=0.7, linestyle='--')\n",
    "    axs[2].hist(time_maxs, bins=time)\n",
    "\n",
    "    axs[0].set_ylabel('Anisotropy')\n",
    "    axs[1].set_ylabel('Activity')\n",
    "    axs[2].set_ylabel('Counts')\n",
    "    axs[2].set_xlabel('Time (min.)')\n",
    "\n",
    "    axs[0].set_yticks([0.2, 0.25, 0.3])\n",
    "    axs[1].set_yticks([])\n",
    "\n",
    "    plt.subplots_adjust(hspace=0)\n",
    "    plt.show()\n",
    "    print('Time of Maximum Activity: %0.1f \\pm %0.1f' % (np.mean(time_maxs), np.std(time_maxs)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
